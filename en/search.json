[{"authors":null,"categories":["R","R:intermediate"],"content":"\r1 Introduction\r2 NCEP\r2.1 Packages\r2.2 Data download\r2.3 Monthly average\r2.4 Visualization\r\r3 ERA-Interim\r3.1 Installation\r3.2 Connection and download with the ECMWF API\r3.3 Processing ncdf\r\r\r\rA friend advised me to introduce R levels as categories. An idea that I now add to each blog post. There are three levels: elementary, intermediate, and advanced. I hope it will help the reader and the R user.\n1 Introduction\rIn this post, I will show how we can download and work directly with data from climatic reanalysis in R. These kind of datasets are a combination of forcast models and data assimilation systems, which allows us to create corrected global grids of recent history of the atmosphere, land surface, and oceans. The two most used reanalyses are NCEP-DO (Reanalysis II) from the NOAA/OAR/ESRL, an improved version of NCEP-NCAR (Reanalysis I), and ERA-Interim from the ECMWF. Since NCEP-DO is the first generation, it is recommended to use third-generation climate reanalysis, especially ERA-Interim. An overview of the current atmospheric reanalysis can be found here. First, let’s see how to access the NCEP data through an R library on CRAN that facilitates the download and handling of the data. Then we will do the same with the ERA-Interim, however, to access this last reanalysis dataset it is necessary to use python and the corresponding API of the ECMWF.\n\r2 NCEP\rTo access the NCEP reanalysis it is required to install the corresponding package RNCEP. The main function is NCEP.gather( ). The resolution of the NCEP reanalysis is 2.5º X 2.5º.\n2.1 Packages\r#install the RNCEP, lubridate and tidyverse packages\rif(!require(\u0026quot;RNCEP\u0026quot;)) install.packages(\u0026quot;RNCEP\u0026quot;)\rif(!require(\u0026quot;lubridate\u0026quot;)) install.packages(\u0026quot;lubridate\u0026quot;)\rif(!require(\u0026quot;tidyverse\u0026quot;)) install.packages(\u0026quot;tidyverse\u0026quot;)\rif(!require(\u0026quot;sf\u0026quot;)) install.packages(\u0026quot;sf\u0026quot;)\r#load the packages\rlibrary(RNCEP)\rlibrary(lubridate) #date and time manipulation\rlibrary(tidyverse) #data manipulation and visualization\rlibrary(RColorBrewer) #color schemes\rlibrary(sf) #to import a spatial object and to work with geom_sf in ggplot2\r\r2.2 Data download\rWe will download the air temperature of the 850haPa pressure level for the year 2016. The variables and pressure levels can be found in the details of the function ?NCEP.gather. The reanalysis2 argument allows us to download both version I and version II, being by default FALSE, that is, we access reanalysis I. In all the requests we will obtain data of every 6 hours (00:00, 06:00, 12:00 and 18:00). This supposes a total of 1464 values for the year 2016.\n#define the necessary arguments\rmonth_range \u0026lt;- c(1,12) #period of months\ryear_range \u0026lt;- c(2016,2016) #period of years\rlat_range \u0026lt;- c(30,60) #latitude range\rlon_range \u0026lt;- c(-30,50) #longitude range\rdata \u0026lt;- NCEP.gather(\u0026quot;air\u0026quot;, #name of the variable\r850, #pressure level 850hPa\rmonth_range,year_range,\rlat_range,lon_range,\rreturn.units = TRUE,\rreanalysis2=TRUE)\r## [1] Units of variable \u0026#39;air\u0026#39; are degK\r## [1] Units of variable \u0026#39;air\u0026#39; are degK\r#dimensions dim(data) \r## [1] 13 33 1464\r#we find lon, lat and time with dimnames()\r#date and time\rdate_time \u0026lt;- dimnames(data)[[3]]\rdate_time \u0026lt;- ymd_h(date_time)\rhead(date_time)\r## [1] \u0026quot;2016-01-01 00:00:00 UTC\u0026quot; \u0026quot;2016-01-01 06:00:00 UTC\u0026quot;\r## [3] \u0026quot;2016-01-01 12:00:00 UTC\u0026quot; \u0026quot;2016-01-01 18:00:00 UTC\u0026quot;\r## [5] \u0026quot;2016-01-02 00:00:00 UTC\u0026quot; \u0026quot;2016-01-02 06:00:00 UTC\u0026quot;\r#longitude and latitude\rlat \u0026lt;- dimnames(data)[[1]]\rlon \u0026lt;- dimnames(data)[[2]]\rhead(lon);head(lat)\r## [1] \u0026quot;-30\u0026quot; \u0026quot;-27.5\u0026quot; \u0026quot;-25\u0026quot; \u0026quot;-22.5\u0026quot; \u0026quot;-20\u0026quot; \u0026quot;-17.5\u0026quot;\r## [1] \u0026quot;60\u0026quot; \u0026quot;57.5\u0026quot; \u0026quot;55\u0026quot; \u0026quot;52.5\u0026quot; \u0026quot;50\u0026quot; \u0026quot;47.5\u0026quot;\r\r2.3 Monthly average\rWe see that the downloaded data is an array of three dimensions with [lat, lon, time]. As above mentioned, we extracted latitude, longitude and time. The temperature is given in Kelvin. The objective in the next section will be to show two maps comparing January and July.\n#create our grouping variable\rgroup \u0026lt;- month(date_time) #estimate the average temperature by month data_month \u0026lt;- aperm(\rapply(\rdata, #our data\rc(1,2), #apply to each time series 1:row, 2:column a the mean( ) function\rby, #group by\rgroup, #months\rfunction(x)ifelse(all(is.na(x)),NA,mean(x))),\rc(2,3,1)) #reorder to get an array like the original\rdim(data_month) #850haPa temperature per month January to December\r## [1] 13 33 12\r\r2.4 Visualization\rOnce we got here, we can visualize the 850hPa temperature of January and July with ggplot2. In this example, I use geom_sf( ) from the library sf, which makes the work easier to visualize spatial objects in ggplot (in the near future I will make a post about sf and ggplot). In the dimension of latitude and longitude we saw that it only indicates a value for each row and column. But we need the coordinates of all the cells in the matrix. To create all combinations between two variables we can use the expand.grid( ) function.\n#first we create all the combinations of lon-lat\rlonlat \u0026lt;- expand.grid(lon=lon,lat=lat)\r#as lonlat was a row/column name, it is character, that\u0026#39;s why we convert it into numeric\rlonlat \u0026lt;- apply(lonlat,2,as.numeric)\r#lon and lat are not in the order as we expect\r#row=lon; column=lat\rdata_month \u0026lt;- aperm(data_month,c(2,1,3))\r#subtract 273.15K to convert K to ºC.\rdf \u0026lt;- data.frame(lonlat,\rTa01=as.vector(data_month[,,1])-273.15,\rTa07=as.vector(data_month[,,7])-273.15)\rBefore we can make the map with ggplot2, we have to adapt the table. The shapefile with the countries limits can be downloaded here.\n#convert the wide table into a long one\rdf \u0026lt;- gather(df,month,Ta,Ta01:Ta07)%\u0026gt;%\rmutate(month=factor(month,unique(month),c(\u0026quot;Jan\u0026quot;,\u0026quot;Jul\u0026quot;)))\r#import the countries limits\rlimit \u0026lt;- st_read(\u0026quot;CNTR_RG_03M_2014.shp\u0026quot;)\r## Reading layer `CNTR_RG_03M_2014\u0026#39; from data source `C:\\Users\\xeo19\\Documents\\GitHub\\blogR\\content\\post\\CNTR_RG_03M_2014.shp\u0026#39; using driver `ESRI Shapefile\u0026#39;\r## Simple feature collection with 256 features and 3 fields\r## geometry type: MULTIPOLYGON\r## dimension: XY\r## bbox: xmin: -180 ymin: -90 xmax: 180 ymax: 83.66068\r## epsg (SRID): NA\r## proj4string: +proj=longlat +ellps=GRS80 +no_defs\r#color scheme\rcolbr \u0026lt;- brewer.pal(11,\u0026quot;RdBu\u0026quot;)\rggplot(df)+\rgeom_tile(aes(lon,lat,fill=Ta))+ #temperature data\rgeom_sf(data=limit,fill=NA,size=.5)+ #limits scale_fill_gradientn(colours=rev(colbr))+\rcoord_sf(ylim=c(30,60),xlim=c(-30,50))+\rscale_x_continuous(breaks=seq(-30,50,10),expand=c(0,0))+\rscale_y_continuous(breaks=seq(30,60,5),expand=c(0,0))+\rlabs(x=\u0026quot;\u0026quot;,y=\u0026quot;\u0026quot;,fill=\u0026quot;Ta 850hPa (ºC)\u0026quot;)+\rfacet_grid(month~.)+ #plot panels by month\rtheme_bw()\r\r\r3 ERA-Interim\rThe ECMWF offers access to its public databases from a pyhton-API. It is required to be registered on the ECMWF website. You can register here. When dealing with another programming language, in R we have to use an interface between both which allows the library reticulate. We must also have installed a pyhton distribution (version 2.x or 3.x). In the case of Windows we can use anaconda.\n3.1 Installation\rif(!require(\u0026quot;reticulate\u0026quot;)) install.packages(\u0026quot;reticulate\u0026quot;)\rif(!require(\u0026quot;ncdf4\u0026quot;)) install.packages(\u0026quot;ncdf4\u0026quot;) #to manage netCDF format\r#load packages\rlibrary(reticulate)\rlibrary(ncdf4)\rOnce we have installed anaconda and the package reticulate, we can install the library python ecmwfapi. We can carry out the installation, or through the Windows CMD using the command conda install -c conda-forge ecmwf-api-client, or with the R function py_install( ) from the reticulate package. The same function allows us to install any python library from R.\n#install the python ECMWF API\rpy_install(\u0026quot;ecmwf-api-client\u0026quot;)\r## ## Installation complete.\r\r3.2 Connection and download with the ECMWF API\rIn order to access the API, it is required to create a file with the user’s information.\nThe “.ecmwfapirc” file must contain the following information:\n{\r\u0026quot;url\u0026quot; : \u0026quot;https://api.ecmwf.int/v1\u0026quot;,\r\u0026quot;key\u0026quot; : \u0026quot;XXXXXXXXXXXXXXXXXXXXXX\u0026quot;,\r\u0026quot;email\u0026quot; : \u0026quot;john.smith@example.com\u0026quot;\r}\rThe key can be obtained with the user account here.\nThe file can be created with the Windows notebook.\nWe create a document “ecmwfapirc.txt”.\rRename this file to “.ecmwfapirc.”\r\rThe last point disappears automatically. Then we save this file in “C:/USERNAME/.ecmwfapirc” or “C:/USERNAME/Documents/.ecmwfapirc”.\n#import the python library ecmwfapi\recmwf \u0026lt;- import(\u0026#39;ecmwfapi\u0026#39;)\r#for this step there must exist the file .ecmwfapirc\rserver = ecmwf$ECMWFDataServer() #start the connection\rOne we get here, how do we create a query? The easiest thing is to go to the website of ECMWF, where we choose the database, in this case ERA-Interim surface, to create a script with all the necessary data. More details about the syntax can be found here. When we proceed on the website, we only have to click on “View MARS Request”. This step takes us to the script in python.\n\r\rWith the syntax of the script from the MARS Request, we can create the query in R.\n#we create the query\rquery \u0026lt;-r_to_py(list(\rclass=\u0026#39;ei\u0026#39;,\rdataset= \u0026quot;interim\u0026quot;, #dataset\rdate= \u0026quot;2017-01-01/to/2017-12-31\u0026quot;, #time period\rexpver= \u0026quot;1\u0026quot;,\rgrid= \u0026quot;0.125/0.125\u0026quot;, #resolution\rlevtype=\u0026quot;sfc\u0026quot;,\rparam= \u0026quot;167.128\u0026quot;, # air temperature (2m)\rarea=\u0026quot;45/-10/30/5\u0026quot;, #N/W/S/E\rstep= \u0026quot;0\u0026quot;,\rstream=\u0026quot;oper\u0026quot;,\rtime=\u0026quot;00:00:00/06:00:00/12:00:00/18:00:00\u0026quot;, #hours\rtype=\u0026quot;an\u0026quot;,\rformat= \u0026quot;netcdf\u0026quot;, #format\rtarget=\u0026#39;ta2017.nc\u0026#39; #file name\r))\r#query to get the ncdf\rserver$retrieve(query)\rThe result is a netCDF file that we can process with the library ncdf4.\n\r3.3 Processing ncdf\rIn the next section, the objective will be the extraction of a time serie from the closest coordinate to a given one. We will use the coordinates of Madrid (40.418889, -3.691944).\n#load packages\rlibrary(sf)\rlibrary(ncdf4)\rlibrary(tidyverse)\r#open the connection with the ncdf file\rnc \u0026lt;- nc_open(\u0026quot;ta2017.nc\u0026quot;)\r#extract lon and lat\rlat \u0026lt;- ncvar_get(nc,\u0026#39;latitude\u0026#39;)\rlon \u0026lt;- ncvar_get(nc,\u0026#39;longitude\u0026#39;)\rdim(lat);dim(lon)\r## [1] 121\r## [1] 121\r#extract the time\rt \u0026lt;- ncvar_get(nc, \u0026quot;time\u0026quot;)\r#time unit: hours since 1900-01-01\rncatt_get(nc,\u0026#39;time\u0026#39;)\r## $units\r## [1] \u0026quot;hours since 1900-01-01 00:00:0.0\u0026quot;\r## ## $long_name\r## [1] \u0026quot;time\u0026quot;\r## ## $calendar\r## [1] \u0026quot;gregorian\u0026quot;\r#convert the hours into date + hour\r#as_datetime() function of the lubridate package needs seconds\rtimestamp \u0026lt;- as_datetime(c(t*60*60),origin=\u0026quot;1900-01-01\u0026quot;)\r#import the data\rdata \u0026lt;- ncvar_get(nc,\u0026quot;t2m\u0026quot;)\r#close the conection with the ncdf file\rnc_close(nc)\rIn this next section we use the sf package, which is replacing the well known sp and rgdal packages.\n#create all the combinations of lon-lat\rlonlat \u0026lt;- expand.grid(lon=lon,lat=lat)\r#we must convert the coordinates in a spatial object sf\r#we also indicate the coordinate system in EPSG code\rcoord \u0026lt;- st_as_sf(lonlat,coords=c(\u0026quot;lon\u0026quot;,\u0026quot;lat\u0026quot;))%\u0026gt;%\rst_set_crs(4326)\r#we do the same with our coordinate of Madrid\rpsj \u0026lt;- st_point(c(-3.691944,40.418889))%\u0026gt;%\rst_sfc()%\u0026gt;%\rst_set_crs(4326)\r#plot all points\rplot(st_geometry(coord))\rplot(psj,add=TRUE,pch = 3, col = \u0026#39;red\u0026#39;)\rIn the next steps we calculate the distance of our reference point to all the grid points. Then we look for the one with less distance.\n#add the distance to the points\rcoord \u0026lt;- mutate(coord,dist=st_distance(coord,psj))\r#create a distance matrix with the same dimensions as our data\rdist_mat \u0026lt;- matrix(coord$dist,dim(data)[-3])\r#the arrayInd function is useful to obtain the row and column indexes\rmat_index \u0026lt;- as.vector(arrayInd(which.min(dist_mat), dim(dist_mat)))\r#we extract the time serie and change the unit from K to ºC\r#we convert the time in date + hour\rdf \u0026lt;- data.frame(ta=data[mat_index[1],mat_index[2],],time=timestamp)%\u0026gt;%\rmutate(ta=ta-273.15,time=ymd_hms(time))\rFinally, we visualize our time series.\nggplot(df,\raes(time,ta))+\rgeom_line()+\rlabs(y=\u0026quot;Temperature (ºC)\u0026quot;,\rx=\u0026quot;\u0026quot;)+\rtheme_bw()\r\r\r","date":1537005584,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537005584,"objectID":"32db3541f80a74cc5b2f80b476bab9af","permalink":"https://dominicroye.github.io/en/2018/access-to-climate-reanalysis-data-from-r/","publishdate":"2018-09-15T10:59:44+01:00","relpermalink":"/en/2018/access-to-climate-reanalysis-data-from-r/","section":"post","summary":"In this post, I will show how we can download and work directly with data from climatic reanalysis in R. These kind of datasets are combination of forcast models and data assimilation systems, which allows us to create corrected global grids of recent history of the atmosphere, land surface, and oceans.","tags":["reanalisis","interim","NCEP/NCAR","era","download","ncdf","access","api","python","ECMWF"],"title":"Access to climate reanalysis data from R","type":"post"},{"authors":null,"categories":["datavis","R","R:elementary"],"content":"Welcome to my blog! I am Dominic Royé, researcher and lecturer of physical geography at the University of Santiago de Compostela. One of my passions is R programming to visualize and analyze any type of data. Hence, my idea of this blog has its origin in my datavis publications I have been cooking in the last year on Twitter on different topics describing the world. In addition, I would like to take advantage of the blog and publish short introductions and explanation on data visualization, management and manipulation in R. I hope you like it. Any suggestion or ideas are welcomed.\nBackground\rI have always wanted to write about the use of the pie chart. The pie chart is widely used in research, teaching, journalism or technical reports. I do not know if it is due to Excel, but even worse than the pie chart itself, is its 3D version (the same for the bar chart). About the 3D versions, I only want to say that they are not recommended, since in these cases the third dimension does not contain any information and therefore it does not help to correctly read the information of the graphic. Regarding the pie chart, among many experts its use is not advised. But why?\nAlready in a study conducted by Simkin and Hastie (1987) they found that the interpretation and processing of angles is more difficult than that of linear forms. Mostly it is easier to read a bar chart than a pie chart. A problem that becomes very visible when we have; 1) too many categories 2) few differences between categories 3) a misuse of colors as legend or 4) comparisons between various pie charts.\nIn general, to decide what possible graphic representations exist for our data, I recommend using the website www.data-to-viz.com or the Financial Times Visual Vocabulary.\n\nWell, now what alternative ways can we use in R?\n\rAlternatives to the pie chart\rThe dataset we will use about the vaccination status of measles correspond to June 2018 in Europe and come from the ECDC.\n#packages\rlibrary(tidyverse)\rlibrary(scales)\rlibrary(RColorBrewer)\r#data\rmeasles \u0026lt;- data.frame(\rvacc_status=c(\u0026quot;Unvaccinated\u0026quot;,\u0026quot;1 Dose\u0026quot;,\r\u0026quot;\u0026gt;= 2 Dose\u0026quot;,\u0026quot;Unkown Dose\u0026quot;,\u0026quot;Unkown\u0026quot;),\rprop=c(0.75,0.091,0.05,0.012,0.096)\r)\r#we order from the highest to the lowest and fix it with a factor\rmeasles \u0026lt;- arrange(measles,\rdesc(prop))%\u0026gt;%\rmutate(vacc_status=factor(vacc_status,vacc_status))\r\r\rvacc_status\rprop\r\r\r\rUnvaccinated\r0.750\r\rUnkown\r0.096\r\r1 Dose\r0.091\r\r\u0026gt;= 2 Dose\r0.050\r\rUnkown Dose\r0.012\r\r\r\rBar plot or similar\rggplot(measles,aes(vacc_status,prop))+\rgeom_bar(stat=\u0026quot;identity\u0026quot;)+\rscale_y_continuous(breaks=seq(0,1,.1),\rlabels=percent, #convert to %\rlimits=c(0,1))+\rlabs(x=\u0026quot;\u0026quot;,y=\u0026quot;\u0026quot;)+\rtheme_minimal()\rggplot(measles,aes(x=vacc_status,prop,ymin=0,ymax=prop))+\rgeom_pointrange()+\rscale_y_continuous(breaks=seq(0,1,.1),\rlabels=percent, #convert to %\rlimits=c(0,1))+\rlabs(x=\u0026quot;\u0026quot;,y=\u0026quot;\u0026quot;)+\rtheme_minimal()\r#custom themes definitions\rtheme_singlebar \u0026lt;- theme_bw()+\rtheme(\rlegend.position = \u0026quot;bottom\u0026quot;,\raxis.title = element_blank(),\raxis.ticks.y = element_blank(),\raxis.text.y = element_blank(),\rpanel.border = element_blank(),\rpanel.grid=element_blank(),\rplot.title=element_text(size=14, face=\u0026quot;bold\u0026quot;)\r)\r#plot\rmutate(measles,\rvacc_status=factor(vacc_status, #we change the order of the categories\rrev(levels(vacc_status))))%\u0026gt;%\rggplot(aes(1,prop,fill=vacc_status))+ #we put 1 in x to create a single bar\rgeom_bar(stat=\u0026quot;identity\u0026quot;)+\rscale_y_continuous(breaks=seq(0,1,.1),\rlabels=percent,\rlimits=c(0,1),\rexpand=c(.01,.01))+\rscale_x_continuous(expand=c(0,0))+\rscale_fill_brewer(\u0026quot;\u0026quot;,palette=\u0026quot;Set1\u0026quot;)+\rcoord_flip()+\rtheme_singlebar\r#we expand our data with numbers from Italy\rmeasles2 \u0026lt;- mutate(measles,\ritaly=c(0.826,0.081,0.053,0.013,0.027),\rvacc_status=factor(vacc_status,rev(levels(vacc_status))))%\u0026gt;%\rrename(europe=\u0026quot;prop\u0026quot;)%\u0026gt;%\rgather(region,prop,europe:italy)\r#plot\rggplot(measles2,aes(region,prop,fill=vacc_status))+\rgeom_bar(stat=\u0026quot;identity\u0026quot;,position=\u0026quot;stack\u0026quot;)+ #stack bar\rscale_y_continuous(breaks=seq(0,1,.1),\rlabels=percent, #convert to %\rlimits=c(0,1),\rexpand=c(0,0))+\rscale_fill_brewer(palette = \u0026quot;Set1\u0026quot;)+\rlabs(x=\u0026quot;\u0026quot;,y=\u0026quot;\u0026quot;,fill=\u0026quot;Vaccination Status\u0026quot;)+\rtheme_minimal()\r\rWaffle plot\r#package\rlibrary(waffle)\r#the waffle function uses a vector with names\rval_measles \u0026lt;- round(measles$prop*100)\rnames(val_measles) \u0026lt;- measles$vacc_status\r#plot\rwaffle(val_measles, #data\rcolors=brewer.pal(5,\u0026quot;Set1\u0026quot;), #colors\rrows=5) #row number \rThe Waffle chart seems very interesting to me when we want to show a proportion of an individual category.\n#data\rmedida \u0026lt;- c(41,59) #data from the OECD 2015\rnames(medida) \u0026lt;- c(\u0026quot;Estudios Superiores\u0026quot;,\u0026quot;Otros estudios\u0026quot;)\r#plot\rwaffle(medida,\rcolors=c(\u0026quot;#377eb8\u0026quot;,\u0026quot;#bdbdbd\u0026quot;),\rrows=5)\r\rTreemap\r#package\rlibrary(treemap)\r#plot\rtreemap(measles,\rindex=\u0026quot;vacc_status\u0026quot;, #variable with categories\rvSize=\u0026quot;prop\u0026quot;, #values\rtype=\u0026quot;index\u0026quot;, #style more in ?treemap\rtitle=\u0026quot;\u0026quot;, palette = brewer.pal(5,\u0026quot;Set1\u0026quot;) #colors\r)\rPersonally, I think that all types of graphic representations have their advantages and disadvantages. However, we currently have a huge variety of alternatives to avoid using the pie chart. If you still want to make a pie chart, which I would not rule out either, I recommend following certain rules, which you can find very well summarized in a recent post by Lisa Charlotte Rost. For example, you should order from the highest to the lowest unless there is a natural order or use a maximum of five categories. Finally, I leave you a link to a cheat sheet from policyviz with basic rules of data visualization. A good reference on graphics using different programs from Excel to R can be found in the book Creating More Effective Graphs (Robbins 2013).\n\rReferences\rRobbins, Naomi B. 2013. Creating More Effective Graphs. a Succinct and Highly Readable Guide to Creating Effective Graph. Chart House.\n\rSimkin, D, and R Hastie. 1987. “An Information-Processing Analysis of Graph Perception.” Journal of the American Statistical Association 82 (398): 454–65.\n\r\r\r\r","date":1534933412,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534933412,"objectID":"207d6132ee5bbd5ab1ba5840d8a9530f","permalink":"https://dominicroye.github.io/en/2018/the-pie-chart/","publishdate":"2018-08-22T11:23:32+01:00","relpermalink":"/en/2018/the-pie-chart/","section":"post","summary":"Welcome to my blog! I am Dominic Royé, researcher and lecturer of physical geography at the University of Santiago de Compostela. One of my passions is R programming to visualize and analyze any type of data. Hence, my idea of this blog has its origin in my datavis publications I have been cooking in the last year on Twitter on different topics describing the world. In addition, I would like to take advantage of the blog and publish short introductions and explanation on data visualization, management and manipulation in R.","tags":["pie chart","data","circular","proportions","first post","treemap","waffle","bar"],"title":"the pie chart","type":"post"},{"authors":["A Vélez","J Martin-Vide","D Royé","O Santaella"],"categories":null,"content":"","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530403200,"objectID":"7bc2a7ffe0ae57e6714ccd7d00de9cc6","permalink":"https://dominicroye.github.io/en/publication/ci_pr_2018/","publishdate":"2018-07-01T00:00:00Z","relpermalink":"/en/publication/ci_pr_2018/","section":"publication","summary":"The present study analyzes spatial patterns of precipitation Concentration Index (CI) in Puerto Rico considering the daily precipitation data of precipitation-gauging stations during 1971-2010. The South and East interior parts of Puerto Rico are characterized by higher CI and the West and North-West parts show lower CI. The annual CI and the rainy season CI show a gradient from South-East to North-West and the dry season CI shows a gradient from South to North. Another difference between the rainy season CI and dry season CI is that the former shows the lowest values of CI while the latter shows the highest values of CI. The different types of seasonal precipitation seem to play a major role on the spatial CI distribution. However, the local relief plays a major role in the spatial patterns due to the effect of the air circulation by the mountains. These findings can contribute to basin-scale water resource management (ooding, soil erosion, etc.) and conservation of the ecological environment.","tags":["Concentration Index","Puerto Rico","precipitation","spatial–temporal patterns"],"title":"Spatial Analysis of Daily Precipitation Concentration in Puerto Rico","type":"publication"},{"authors":["D Royé","MT Zarrabeitia","P Fdez-Arroyabe","A Álvarez-Gutiérrez","A Santurtún"],"categories":null,"content":"","date":1525132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525132800,"objectID":"9386a67b5c062730063f0a60839e8ab3","permalink":"https://dominicroye.github.io/en/publication/iam_cantabria_2018/","publishdate":"2018-05-01T00:00:00Z","relpermalink":"/en/publication/iam_cantabria_2018/","section":"publication","summary":"Introduction and objectives. The role of the environment on cardiovascular health is becoming more prominent in the context of global change. The aim of this study was to analyze the relationship between apparent temperature (AT) and air pollutants and acute myocardial infarction (AMI) and to study the temporal pattern of this disease and its associated mortality. Methods. We performed a time-series study of admissions for AMI in Cantabria between 2001 and 2015. The association between environmental variables (including a biometeorological index, apparent AT) and AMI was analyzed using a quasi-Poisson regression model. To assess potential delayed and non-linear effects of these variables on AMI, a lag non-linear model was fitted in a generalized additive model. Results. The incidence rate and the mortality followed a downward trend during the study period (CC=–0.714; P=.0002). An annual pattern was found in hospital admissions (P=.005), with the highest values being registered in winter; a weekly trend was also identified, reaching a minimum during the weekends (P=.000005). There was an inverse association between AT and the number of hospital admissions due to AMI and a direct association with particulate matter with a diameter smaller than 10 μm. Conclusions. Hospital admissions for AMI followed a downward trend between 2007 and 2015. Mortality associated with admissions due to this diagnosis has decreased. Predictive factors for this disease were AT and particulate matter with a diameter smaller than 10 μm.","tags":["Acute myocardial infarction","Apparent temperature","Air pollutants","Particulate matter"],"title":"Role of Apparent Temperature and Air Pollutants in Hospital Admissions for Acute Myocardial Infarction in the North of Spain","type":"publication"},{"authors":["D Royé","A Figueiras","M Taracido-Trunk"],"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"8c48be3d65e4bed0ce4fe5203eb06bb0","permalink":"https://dominicroye.github.io/en/publication/pharma_coru%C3%B1a_2018/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/en/publication/pharma_coru%C3%B1a_2018/","section":"publication","summary":"The consumption of medication, especially over-the-counter (OTC) drugs, can reflect environmental exposure with a lesser degree of severity in terms of morbidity. The non-linear effects of maximum and minimum apparent temperature on respiratory drug sales in A Coruña from 2006 to 2010 were examined using a distributed lag non-linear model. In particular, low apparent temperatures proved to be associated with increased sales of respiratory drugs. The strongest consistent risk estimates were found for minimum apparent temperatures in respiratory drug sales with an increase of 33.4% (95% CI: 12.5-58.0%) when the temperature changed from 2.8 ºC to −1.4 ºC. These findings may serve to guide the planning of public health interventions in order to predict and manage the health effects of exposure to the thermal environment for lower degrees of morbidity. More precisely, significant increases in the use of measured OTC medication could be used to identify and anticipate influenza outbreaks due to a more sensitive degree of the data source.","tags":["drug sales","pharmacoepidemiology","respiratory cause","short‐term effects","Spain","thermal environment"],"title":"Short-term effects of heat and cold on respiratory drug use. A time-series epidemiological study in A Coruña, Spain","type":"publication"},{"authors":["D Royé","N Lorenzo","J Martin-Vide"],"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"fd71c0d62978df70b5d41813df70acdf","permalink":"https://dominicroye.github.io/en/publication/lightning_galicia_2018/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/en/publication/lightning_galicia_2018/","section":"publication","summary":"The spatial-temporal patterns of cloud-to-ground (CG) lightning covering the period 2010-2015 over the northwest Iberian Peninsula were investigated. The analysis conducted employed three main methods: the circulation weather types developed by Jenkinson \u0026 Collison, the fit of a generalized additive model for geographic variables and the use of a concentration index for the ratio of lightning strikes and thunderstorm days. The main activity in the summer months can be attributed to situations with eastern or anticyclonic flow due to convection by insolation. In winter, lightning proves to have a frontal origin and is mainly associated with western or cyclonic flow situations which occur with advections of air masses of maritime origin. The largest number of CG discharges occurs under eastern flow and their hybrids with anticyclonic situations. Thunderstorms with greater CG lightning activity, highlighted by a higher Concentration Index, are located in areas with a higher density of lightning strikes, above all in mountainous areas away from the sea. The modeling of lightning density with geographic variables shows the positive influence of altitude and, particularly, distance to the sea, with nonlinear relationships due to the complex orography of the region. Likewise, areas with convex topography receive more lightning strikes than concave ones, a relation which has been demonstrated for the first time from a Generalized Additive Model (GAM).","tags":["thunderstorm","Iberian Peninsula","Concentration Index","weather types","Convexity Index","Generalized Additive Model","cloud-to-ground lightning"],"title":"Spatial–temporal patterns of cloud-to-ground lightning over the northwest Iberian Peninsula during the period 2010–2015","type":"publication"},{"authors":["S Mathbout","JA Lopez-Bustins","D Royé","J Martin-Vide","J Bech","FS Rodrigo"],"categories":null,"content":"","date":1509494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509494400,"objectID":"832515af53727ef93d76e569e64aef88","permalink":"https://dominicroye.github.io/en/publication/appliedgeophysics_2017_en/","publishdate":"2017-11-01T00:00:00Z","relpermalink":"/en/publication/appliedgeophysics_2017_en/","section":"publication","summary":"The Eastern Mediterranean is one of the most prominent hot spots of climate change in the world and extreme climatic phenomena in this region such as drought or extreme rainfall events are expected to become more frequent and intense. In this study climate extreme indices recommended by the joint World Meteorological Organization Expert Team on Climate Change Detection and Indices are calculated for daily precipitation data in 70 weather stations during 1961–2012. Observed trends and changes in daily precipitation extremes over the EM basin were analysed using the RClimDex package, which was developed by the Climate Research Branch of the Meteorological Service of Canada. Extreme and heavy precipitation events showed globally a statistically significant decrease in the Eastern Mediterranean and, in the southern parts, a significant decrease in total precipitation. The overall analysis of extreme precipitation indices reveals that decreasing trends are generally more frequent than increasing trends. We found statistically significant decreasing trends (reaching 74% of stations for extremely wet days) and increasing trends (reaching 36% of stations for number of very heavy precipitation days). Finally, most of the extreme precipitation indices have a statistically significant positive correlation with annual precipitation, particularly the number of heavy and very heavy precipitation days.","tags":["Eastern Mediterranean","extreme precipitation","trend","spatial temporal distribution"],"title":"Observed Changes in Daily Precipitation Extremes at Annual Timescale Over the Eastern Mediterranean During 1961–2012","type":"publication"},{"authors":["S Mathbout","JA Lopez-Bustins","D Royé","J Martin-Vide","J Bech","FS Rodrigo"],"categories":null,"content":"","date":1509494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509494400,"objectID":"cbd2c2e7af4696d9f07ee5032f37b802","permalink":"https://dominicroye.github.io/en/publication/appliedgeophysics_2017_es/","publishdate":"2017-11-01T00:00:00Z","relpermalink":"/en/publication/appliedgeophysics_2017_es/","section":"publication","summary":"The Eastern Mediterranean is one of the most prominent hot spots of climate change in the world and extreme climatic phenomena in this region such as drought or extreme rainfall events are expected to become more frequent and intense. In this study climate extreme indices recommended by the joint World Meteorological Organization Expert Team on Climate Change Detection and Indices are calculated for daily precipitation data in 70 weather stations during 1961–2012. Observed trends and changes in daily precipitation extremes over the EM basin were analysed using the RClimDex package, which was developed by the Climate Research Branch of the Meteorological Service of Canada. Extreme and heavy precipitation events showed globally a statistically significant decrease in the Eastern Mediterranean and, in the southern parts, a significant decrease in total precipitation. The overall analysis of extreme precipitation indices reveals that decreasing trends are generally more frequent than increasing trends. We found statistically significant decreasing trends (reaching 74% of stations for extremely wet days) and increasing trends (reaching 36% of stations for number of very heavy precipitation days). Finally, most of the extreme precipitation indices have a statistically significant positive correlation with annual precipitation, particularly the number of heavy and very heavy precipitation days.","tags":["Eastern Mediterranean","extreme precipitation","trend","spatial temporal distribution"],"title":"Observed Changes in Daily Precipitation Extremes at Annual Timescale Over the Eastern Mediterranean During 1961–2012","type":"publication"},{"authors":["D Royé"],"categories":null,"content":"","date":1501545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501545600,"objectID":"735acb4c3b633c5b3cfad91a943dfb61","permalink":"https://dominicroye.github.io/en/publication/hotnights_bcn_2017/","publishdate":"2017-08-01T00:00:00Z","relpermalink":"/en/publication/hotnights_bcn_2017/","section":"publication","summary":"Heat-related effects on mortality have been widely analyzed using maximum and minimum temperatures as exposure variables. Nevertheless, the main focus is usually on the former with the minimum temperature being limited in use as far as human health effects are concerned. Therefore, new thermal indices were used in this research to describe the duration of night hours with air temperatures higher than the 95% percentile of the minimum temperature (Hot Night hours) and intensity as the summation of these air temperatures in degrees (Hot Night degrees). An exposure-response relationship between mortality due to natural, respiratory and cardiovascular causes and summer night temperatures was assessed using data from the Barcelona region between 2003 and 2013. The non-linear relationship between the exposure and response variables was modeled using a distributed lag non-linear model. The estimated associations for both exposure variables and mortality shows a relationship with high and medium values that persist significantly up to a lag of 1–2 days. In mortality due to natural causes an increase of 1.1% per 10% (CI95% 0.6–1.5) for Hot Night hours and 5.8% per each 10º (CI95% 3.5–8.2%) for Hot Night degrees is observed. The effects of Hot Night hours reach their maximum with 100% and leads to an increase by 9.2% (CI95% 5.3–13.1%). The hourly description of night heat effects reduced to a single indicator in duration and intensity is a new approach and shows a different perspective and significant heat-related effects on human health.","tags":["heat","mortality","tropical night","hot night","effects","human health","climate change"],"title":"The effects of hot nights on mortality in Barcelona, Spain","type":"publication"},{"authors":["D Royé","J Martin-Vide"],"categories":null,"content":"","date":1496275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496275200,"objectID":"83752c0287cd3c7c14fd70c98985fa6b","permalink":"https://dominicroye.github.io/en/publication/usa_ci_2017/","publishdate":"2017-06-01T00:00:00Z","relpermalink":"/en/publication/usa_ci_2017/","section":"publication","summary":"The contiguous US exhibits a wide variety of precipitation regimes, first, because of the wide range of latitudes and altitudes. The physiographic units with a basic meridional configuration contribute to the differentiation between east and west in the country while generating some large interior continental spaces. The frequency distribution of daily precipitation amounts almost anywhere conforms to a negative exponential distribution, reflecting the fact that there are many small daily totals and few large ones. Positive exponential curves, which plot the cumulative percentages of days with precipitation against the cumulative percentage of the rainfall amounts that they contribute, can be evaluated through the Concentration Index. The Concentration Index has been applied to the contiguous United States using a gridded climate dataset of daily precipitation data, at a resolution of 0.25°, provided by CPC/NOAA/OAR/Earth System Research Laboratory, for the period between 1956 and 2006. At the same time, other rainfall indices and variables such as the annual coefficient of variation, seasonal rainfall regimes and the probabilities of a day with precipitation have been presented with a view to explaining spatial CI patterns. The spatial distribution of the CI in the contiguous United States is geographically consistent, reflecting the principal physiographic and climatic units of the country. Likewise, linear correlations have been established between the CI and geographical factors such as latitude, longitude and altitude. In the latter case the Pearson correlation coefficient (r) between this factor and the CI is −0.51 (p-value ","tags":["Concentration Index","Contiguous United States","daily precipitation","precipitation indices","spatial–temporal patterns"],"title":"Concentration of Daily Precipitation in the Contiguous United States","type":"publication"},{"authors":["P Fdez-Arroyabe","D Royé"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"389371f80a93c479ccb639ee58c2c7bf","permalink":"https://dominicroye.github.io/en/publication/chapter_springer_2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/en/publication/chapter_springer_2017/","section":"publication","summary":"Co-creation of scientific knowledge based on new technologies and big data sources is one of the main challenges for the digital society in the XXI century. Data management and the analysis of patterns among datasets based on machine learning and artificial intelligence has become essential for many sectors nowadays. The development of real time health-related climate services represents an example where abundant structured and unstructured information and transdisciplinary research are needed. The study of the interactions between atmospheric processes and human health through a big data approach can reveal the hidden value of data. The Oxyalert technological platform is presented as an example of a digital biometeorological infrastructure able to forecast, at an individual level, oxygen changes impacts on human health.","tags":["co-creation","interdisciplinarity","transdisciplinarity","morbidity","climate services","digital divide","big data","health"],"title":"Co-creation and Participatory Design of Big Data Infrastructures on the Field of Human Health Related Climate Services","type":"publication"},{"authors":["D Royé","J Taboada","A Ezpeleta-Martí","N Lorenzo"],"categories":null,"content":"","date":1459468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1459468800,"objectID":"c3bdb9563e443f7fc44c7b7eeece88b4","permalink":"https://dominicroye.github.io/en/publication/cwt_galicia_resp_2016/","publishdate":"2016-04-01T00:00:00Z","relpermalink":"/en/publication/cwt_galicia_resp_2016/","section":"publication","summary":"The link between various pathologies and atmospheric conditions has been a constant topic of study over recent decades in many places across the world; knowing more about it enables us to pre-empt the worsening of certain diseases, thereby optimizing medical resources. This study looked specifically at the connections in winter between respiratory diseases and types of atmospheric weather conditions (Circulation Weather Types, CWT) in Galicia, a region in the north-western corner of the Iberian Peninsula. To do this, the study used hospital admission data associated with these pathologies as well as an automatic classification of weather types. The main result obtained was that weather types giving rise to an increase in admissions due to these diseases are those associated with cold, dry weather, such as those in the east and south-east, or anticyclonic types. A second peak was associated with humid, hotter weather, generally linked to south-west weather types. In the future, this result may help to forecast the increase in respiratory pathologies in the region some days in advance.","tags":["weather type","respiratory diseases","hospital admissions","human health","Spain"],"title":"Winter circulation weather types and hospital admissions for respiratory diseases in Galicia, Spain","type":"publication"},{"authors":["D Royé","A Ezpeleta-Martí"],"categories":null,"content":"","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448928000,"objectID":"48e40344ca1e4f7a2ab2a6c4510aa260","permalink":"https://dominicroye.github.io/en/publication/hotnights_age_2015/","publishdate":"2015-12-01T00:00:00Z","relpermalink":"/en/publication/hotnights_age_2015/","section":"publication","summary":"Analysis of tropical nights on the Atlantic coast of the Iberian peninsula. A proposed methodology. This paper presents a new methodology for the study of warm nights, also called «tropical», in Galicia and Portugal in order to identify those nights where people can be affected by heat stress. The use of two indicators obtained through half-hourly data has allowed us to define in more detail the thermal characteristics of the nights between May and October, thereby being able to more accurately assess the risk to the health and well-being of the population. There is a significant increase in the frequency of tropical nights and warm nights on the Atlantic coast, from the north of Galicia to the south of Portugal. The lower latitude and proximity to the coastline are associated with greater persistence of heat and thermal stress during these nights. In inland areas the persistence is less. The warmest nights are more frequent and intense in centres of the cities, due to the effect of the urban heat island.","tags":["tropical night","thermic stress","heat island","Galicia","Portugal"],"title":"Analysis of tropical nights on the atlantic coast of the Iberian Peninsula. A proposed methodology","type":"publication"},{"authors":["D Royé"],"categories":null,"content":"Used datasets are available for download here. Alternative datasets for Spain in ncdf format can be downloaded:\nAEMET\n Gridded 20km and 50km (precipitation and temperature)\n Gridded 5km (precipitation)\n  CSIC\n Gridded 5km (precipitation)  ","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448928000,"objectID":"28a50037c73f6b009121b5250e4fe2d1","permalink":"https://dominicroye.github.io/en/publication/ncdf_2015/","publishdate":"2015-12-01T00:00:00Z","relpermalink":"/en/publication/ncdf_2015/","section":"publication","summary":"A practical introduction in the use of netCDF in the environment of R Spatio-temporal data is currently key to many disciplines, especially to climatology and meteorology. A widespread format is netCDF allowing a multidimensional structure and an exchange of data machine independently. In this article, we introduce the use of these databases with the free software environment R. To do this, we will work with a grid of the maximum temperature of the Iberian Peninsula for the period 1971-2007. The goal is to read and visualize the netCDF format, and make some fist overall and specifi calculations. Finally the applicability is shown in a case study: the diurnal temperature variation in the Iberian Peninsula for January and August 2006. (Spanish)","tags":["netCDF","R","climatology","temperature","matrix","database"],"title":"The use of climate databases netCDF with array structure in the environment of R","type":"publication"}]